# -*- coding: utf-8 -*-
"""Final_Model (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EN22ZR5QtI6QLWl7xYrO_l3pGSxnZ107
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from scipy.stats import randint
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier

df=pd.read_csv("data.csv")

df

df.isna().sum()

df=df.fillna(df.mean())

df.info()

df.isna().sum()

X=df[['DerogCnt', 'CollectCnt', 'BanruptcyInd', 'InqCnt06', 'InqFinanceCnt24', 'TLTimeFirst', 'TLTimeLast', 'TLCnt', 'TLSum', 'TLMaxSum', 'TLDel60Cnt', 'TLBadCnt24']]
y=df['TARGET']

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.9,
                                                    random_state=50,
                                                    )

sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

import joblib
joblib.dump(sc, 'Normalisation_Data')

classifier =  LogisticRegression()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)

joblib.dump(classifier, 'Classifier_Model')

print(confusion_matrix(y_test,y_pred))

print(accuracy_score(y_test, y_pred)*100)

import pandas as pd

def predictor(Derogatory_Count, No_of_Accounts_Turned_to_Collection_Account, Bankruptcy_Indicator, Inquiry_Count_in_Last_6_Months, Inquiry_Count_for_Finance_Related_Purposes_in_Last_24_Months, Time_Since_Opening_the_First_Credit_Line_in_Days, Time_Since_Opening_the_Most_Recent_Credit_Line_in_Days, Total_Count_of_Active_Credit_Lines, Total_Credit_Line_Sum_in_USD, Total_Maximum_Credit_Line_Sum_in_USD, Total_Count_of_Credit_Lines_Delinquent_by_60_Days_or_More, Total_Bad_Credit_Line_Count_in_the_Last_24_Months):
    data = {
        'DerogCnt': [Derogatory_Count],
        'CollectCnt': [No_of_Accounts_Turned_to_Collection_Account],
        'BanruptcyInd': [Bankruptcy_Indicator],
        'InqCnt06': [Inquiry_Count_in_Last_6_Months],
        'InqFinanceCnt24': [Inquiry_Count_for_Finance_Related_Purposes_in_Last_24_Months],
        'TLTimeFirst': [Time_Since_Opening_the_First_Credit_Line_in_Days],
        'TLTimeLast': [Time_Since_Opening_the_Most_Recent_Credit_Line_in_Days],
        'TLCnt': [Total_Count_of_Active_Credit_Lines],
        'TLSum': [Total_Credit_Line_Sum_in_USD],
        'TLMaxSum': [Total_Maximum_Credit_Line_Sum_in_USD],
        'TLDel60Cnt': [Total_Count_of_Credit_Lines_Delinquent_by_60_Days_or_More],
        'TLBadCnt24': [Total_Bad_Credit_Line_Count_in_the_Last_24_Months]
    }
    df = pd.DataFrame(data)
    arr = np.array(df)
    predict = classifier.predict(arr)
    if predict == 0:
        return "High Risk"
    else:
        return "Low Risk"

import gradio as gr
demo = gr.Interface(
    fn=predictor,
    inputs=["number","number","number","number","number","number","number","number","number","number","number","number"],
    outputs=["text"],
)
demo.launch()

